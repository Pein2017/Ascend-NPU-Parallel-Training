training:
  lr: 1e-1
  batch_size: 256
  verbose: false
  seed: 17
  hist_record_num: 15
  train_ratio: 0.9
  test_ratio: 0.05
  print_freq: 300
  workers: 0
  start_epoch: 0
  epochs: 3000
  debug_mode: false
  tracker: false
  checkpoint_folder: /data/Pein/Pytorch/Ascend-NPU-Parallel-Training/checkpoints
  checkpoint_path:

model:
  arch: resnet34
  pretrained: false

optimizer:
  name: SGD
  momentum: 0.9
  weight_decay: 5e-4
  betas: [0.9, 0.99]
  criterion: CrossEntropyLoss

scheduler:
  type: ReduceLROnPlateau
  mode: min
  factor: 0.2 # for lr reduction
  patience: 100
  warmup_iters: 0

early_stopping:
  delta: 1e-4
  patience: 200

data:
  path: /data/Pein/Pytorch/Ascend-NPU-Parallel-Training/cifar100_data
  dataset_name: cifar100
  dummy: false

logging:
  tb_log_dir: /data/Pein/Pytorch/Ascend-NPU-Parallel-Training/3-tb_logs/
  # checkpoint_folder: /data/Pein/Pytorch/Ascend-NPU-Parallel-Training/checkpoints
  # checkpoint_path:

evaluation:
  evaluate: true

distributed_training:
  distributed: true
  world_size: 1
  rank: 0
  dist_url: tcp://192.168.18.48:12345
  dist_backend: hccl
  master_addr: 192.168.18.48
  master_port: 12345
  multiprocessing_distributed: true
  gpu: None
  device: npu
  device_list: [0, 1, 2, 3, 4, 5, 6, 7]

amp:
  enabled: false
  loss_scale: 1024.
  opt_level: O0
